{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37f4daaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2900ee3",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ce09c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vtr_b\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5c1f8",
   "metadata": {},
   "source": [
    "# Algumas informações sobre como funciona as siglas\n",
    "\n",
    "#### A base (conjunto de dados) é conhecido como corpus e os corpous são formados por documentos que no caso é cada artigo dento do arquivo.  Separando as palavras de cada documentos temos os tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccdf71d",
   "metadata": {},
   "source": [
    "# Funções "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c0ae86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega a lista de tokens que contém as pontuações e retorna somente as palavras\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras\n",
    "\n",
    "# Normaliza as palavras dentros da lista\n",
    "def normalizacao(lista_palavras): # altera lista\n",
    "    for i in range(len(lista_palavras)):\n",
    "        lista_palavras[i] = lista_palavras[i].lower()\n",
    "        \n",
    "# cria devolve uma nova lista sem alterar a antiga\n",
    "def normalizacao_nova_lista(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada\n",
    "\n",
    "# Devolve um set normalizado e sem as pontuações\n",
    "def sep_norm_npdup_alt_list(lista_tokens):\n",
    "    for i in range(len(lista_tokens)):\n",
    "        if lista_tokens[i].isalpha():\n",
    "            lista_tokens[i] = lista_tokens[i].lower()\n",
    "        return set(lista_tokens)\n",
    "    \n",
    "def sep_norm_nodup(lista_tokens):\n",
    "    lista_palavra = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavra.append(token.lower())\n",
    "    return set(lista_palavra)\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / 18464 # total de palavras\n",
    "    \n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, 'r', encoding = 'utf-8')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close\n",
    "    return lista_palavras_teste\n",
    "\n",
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        palavra_corrigida_novo = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta or palavra_corrigida_novo == correta:\n",
    "            acertou += 1  \n",
    "            \n",
    "    taxa_desconhecida = desconhecida/numero_palavras\n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "    print(f'taxa de acerto -> {acertou} ({taxa_acerto*100:.2f}%) de {numero_palavras} palavras.')\n",
    "    print(f'Quantidade de palavras desconhecidas {desconhecida} ({taxa_desconhecida*100:.2f}%)')\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "            novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key= probabilidade)\n",
    "    return palavra_correta\n",
    "def corretor_final(palavra):\n",
    "    palavra_correta = novo_corretor(palavra)\n",
    "    palavra_correta_2 = corretor(palavra)\n",
    "    lista_palavra1 = []\n",
    "    lista_palavra2 = []\n",
    "    for i in palavra_correta:\n",
    "        lista_palavra1.append(i in palavra)\n",
    "    for i in palavra:\n",
    "        lista_palavra2.append(i in palavra)\n",
    "    if sum(lista_palavra1) > sum(lista_palavra2):\n",
    "        return palavra_correta\n",
    "    else:\n",
    "        return palavra_correta_2\n",
    "    \n",
    "def avaliador_teste(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor_final(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_desconhecida = desconhecida/numero_palavras\n",
    "    taxa_acerto = acertou/numero_palavras\n",
    "    print(f'taxa de acerto -> {acertou} ({taxa_acerto*100:.2f}%) de {numero_palavras} palavras.')\n",
    "    print(f'Quantidade de palavras desconhecidas {desconhecida} ({taxa_desconhecida*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64691b53",
   "metadata": {},
   "source": [
    "# Inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5c313df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artigos.txt', 'r', encoding = 'utf-8') as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c3cc7323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4c3ec3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artigos) #números de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c56ece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Olá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b45743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:['Olá,', 'tudo', 'bem?'], e o tamanho da lista de tokens: 3\n"
     ]
    }
   ],
   "source": [
    "# não resolve todo o problema, pois coloca as palavras junto com as pontuações\n",
    "texto_exemplo = 'Olá, tudo bem?'\n",
    "tokens = texto_exemplo.split() # separar em tokens\n",
    "print(f'Tokens:{tokens}, e o tamanho da lista de tokens: {len(tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a48a6fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cria uma lista com cada palavra e pontuação de forma separada\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af9f98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tamanho da lista de tokens junto com as pontuaões: 5\n"
     ]
    }
   ],
   "source": [
    "# precisamos somente de palavras. Nesse caso temos as palavras e as pontuações.\n",
    "print(f' Tamanho da lista de tokens junto com as pontuaões: {len(palavras_separadas)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dd04ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bb27d05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da lista de tokens com as pontuações -> 515827\n",
      "Tamanho da lista de palavras sem as pontuações -> 403031\n",
      "CPU times: total: 12.1 s\n",
      "Wall time: 55.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos) # separa os tokens do corpus\n",
    "lista_palavras = separa_palavras(lista_tokens) # retorna somente as palavras da lista de tokens do copus\n",
    "print(f'Tamanho da lista de tokens com as pontuações -> {len(lista_tokens)}')\n",
    "print(f'Tamanho da lista de palavras sem as pontuações -> {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6503286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros valores da lista antes de ser normalizada -> ['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(f'Primeiros valores da lista antes de ser normalizada -> {lista_palavras[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b4ec39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_normalizada = normalizacao_nova_lista(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f63e7ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiros valores da lista após ser normalizada -> ['imagem', 'temos', 'a']\n"
     ]
    }
   ],
   "source": [
    "print(f'Primeiros valores da lista após ser normalizada -> {lista_normalizada[:3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4ad70b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de palavras únicas na lista nomalizada 18464\n",
      "Quantidade de palavras geradas forma: 264\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de palavras que podem ser corrigidas e a quantidade de palava gerada por meio da palara errada lgica\n",
    "total_de_palavras = len(set(lista_normalizada))\n",
    "print(f'Quantidade de palavras únicas na lista normalizada {total_de_palavras}')\n",
    "palavras_geradas = gerador_palavras('lgica')\n",
    "print(f'Quantidade de palavras geradas forma: {len(palavras_geradas)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "30586dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502), ('o', 14056), ('que', 12230), ('a', 11099), ('e', 10501)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criando lista de frequencia das palavras\n",
    "frequencia = nltk.FreqDist(lista_normalizada) # retora uma lista de tuplas com a palavra e a quantidade de vezes\n",
    "# que a palavra aparece no curpus\n",
    "frequencia.most_common(5) # mostra as 5 palavras que maus aparecem no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "16ad3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testando corretor\n",
    "corretor('lgica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "65178026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a lista de teste\n",
    "lista_teste = cria_dados_teste('palavras.txt')\n",
    "lista_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c0bba4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto -> 142 (76.34%) de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "# testanto o corretor coma função do avaliador\n",
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d35de349",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f68eb016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto -> 142 (76.34%) de 186 palavras.\n",
      "Quantidade de palavras desconhecidas 13 (6.99%)\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste, vocabulario) # esse foi o resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a7ae344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto -> 103 (55.38%) de 186 palavras.\n",
      "Quantidade de palavras desconhecidas 13 (6.99%)\n"
     ]
    }
   ],
   "source": [
    "#teste com o novo corretor\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e9f272c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tentar juntar os dois corretores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4a4e2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto -> 159 (85.48%) de 186 palavras.\n",
      "Quantidade de palavras desconhecidas 13 (6.99%)\n"
     ]
    }
   ],
   "source": [
    "#testando com as duas palavras\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "44b29127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa de acerto -> 142 (76.34%) de 186 palavras.\n",
      "Quantidade de palavras desconhecidas 13 (6.99%)\n"
     ]
    }
   ],
   "source": [
    "avaliador_teste(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48f3e93-b7e1-44eb-a4ad-9442756cfad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       " 'APPDATA': 'C:\\\\Users\\\\vtr_b\\\\AppData\\\\Roaming',\n",
       " 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       " 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMPUTERNAME': 'VICTOR-BUITONI',\n",
       " 'COMSPEC': 'C:\\\\Windows\\\\system32\\\\cmd.exe',\n",
       " 'CONDA_DEFAULT_ENV': 'base',\n",
       " 'CONDA_EXE': 'D:\\\\Anaconda\\\\Scripts\\\\conda.exe',\n",
       " 'CONDA_PROMPT_MODIFIER': '(base) ',\n",
       " 'CONDA_PYTHON_EXE': 'D:\\\\Anaconda\\\\python.exe',\n",
       " 'CONDA_SHLVL': '1',\n",
       " 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData',\n",
       " 'EFC_9628': '1',\n",
       " 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer',\n",
       " 'FPS_BROWSER_USER_PROFILE_STRING': 'Default',\n",
       " 'HOMEDRIVE': 'C:',\n",
       " 'HOMEPATH': '\\\\Users\\\\vtr_b',\n",
       " 'LOCALAPPDATA': 'C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local',\n",
       " 'LOGONSERVER': '\\\\\\\\VICTOR-BUITONI',\n",
       " 'NUMBER_OF_PROCESSORS': '16',\n",
       " 'ONEDRIVE': 'C:\\\\Users\\\\vtr_b\\\\OneDrive',\n",
       " 'ONEDRIVECONSUMER': 'C:\\\\Users\\\\vtr_b\\\\OneDrive',\n",
       " 'OS': 'Windows_NT',\n",
       " 'PATH': 'D:\\\\Anaconda;D:\\\\Anaconda\\\\Library\\\\mingw-w64\\\\bin;D:\\\\Anaconda\\\\Library\\\\usr\\\\bin;D:\\\\Anaconda\\\\Library\\\\bin;D:\\\\Anaconda\\\\Scripts;D:\\\\Anaconda\\\\bin;D:\\\\Anaconda\\\\condabin;D:\\\\Anaconda;D:\\\\Anaconda\\\\Library\\\\mingw-w64\\\\bin;D:\\\\Anaconda\\\\Library\\\\usr\\\\bin;D:\\\\Anaconda\\\\Library\\\\bin;D:\\\\Anaconda\\\\Scripts;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Windows\\\\system32;C:\\\\Windows;C:\\\\Windows\\\\System32\\\\Wbem;C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\Windows\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\dotnet;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA NvDLISR;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local\\\\Programs\\\\mongosh',\n",
       " 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC',\n",
       " 'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       " 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 154 Stepping 3, GenuineIntel',\n",
       " 'PROCESSOR_LEVEL': '6',\n",
       " 'PROCESSOR_REVISION': '9a03',\n",
       " 'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       " 'PROGRAMFILES': 'C:\\\\Program Files',\n",
       " 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       " 'PROGRAMW6432': 'C:\\\\Program Files',\n",
       " 'PROMPT': '(base) $P$G',\n",
       " 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\Windows\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules',\n",
       " 'PT8HOME': 'C:\\\\Program Files\\\\Cisco Packet Tracer 8.2.0',\n",
       " 'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       " 'SESSIONNAME': 'Console',\n",
       " 'SYSTEMDRIVE': 'C:',\n",
       " 'SYSTEMROOT': 'C:\\\\Windows',\n",
       " 'TEMP': 'C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local\\\\Temp',\n",
       " 'TMP': 'C:\\\\Users\\\\vtr_b\\\\AppData\\\\Local\\\\Temp',\n",
       " 'USERDOMAIN': 'VICTOR-BUITONI',\n",
       " 'USERDOMAIN_ROAMINGPROFILE': 'VICTOR-BUITONI',\n",
       " 'USERNAME': 'vtr_b',\n",
       " 'USERPROFILE': 'C:\\\\Users\\\\vtr_b',\n",
       " 'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\',\n",
       " 'WINDIR': 'C:\\\\Windows',\n",
       " 'ZES_ENABLE_SYSMAN': '1',\n",
       " 'CONDA_PREFIX': 'D:\\\\Anaconda',\n",
       " 'CONDA_ROOT': 'D:\\\\Anaconda',\n",
       " 'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       " 'JPY_SESSION_NAME': 'projetos_python/Machine learning/NLP/cf349809-e8af-404f-83cd-8a6df751b244',\n",
       " 'JPY_INTERRUPT_EVENT': '7480',\n",
       " 'IPY_INTERRUPT_EVENT': '7480',\n",
       " 'JPY_PARENT_PID': '6840',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'FORCE_COLOR': '1',\n",
       " 'CLICOLOR_FORCE': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c034c-d1c7-46b2-b2d3-bea2466130bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
